{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c5517c9-eab1-483c-80a2-e332fc57d686",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import copy\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13c94faf-8d6c-44aa-9618-7192902b1933",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_original_dataset, load_deleted_dataset\n",
    "from models import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d524cc-f9e7-4806-af84-a4429d0e47e0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'Datasets/Features/'\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "PERCENTAGES = [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a614e7-46f8-451b-aa48-9624b48efe77",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('results/unrolling-sgd', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabe569d-1a5f-4a7f-b90c-5144bafa7a29",
   "metadata": {},
   "source": [
    "# finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24e1d64a-eb5d-4980-ac01-73000360b291",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit(model, save_dir, train_set, test_set, forget_set):\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # prepare model\n",
    "    \n",
    "    # https://github.com/cleverhans-lab/unrolling-sgd/blob/main/Unlearning/finetune.py#L94\n",
    "    M = copy.deepcopy(model)\n",
    "    \n",
    "    # https://github.com/cleverhans-lab/unrolling-sgd/blob/main/Unlearning/finetune.py#L150\n",
    "    M_unlearned = copy.deepcopy(model)\n",
    "        \n",
    "    M_unlearned.train()\n",
    "    \n",
    "    # https://github.com/cleverhans-lab/unrolling-sgd/blob/main/Unlearning/finetune.py#L131\n",
    "    error = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    forget_loader = torch.utils.data.DataLoader(forget_set, batch_size = BATCH_SIZE, shuffle = True, drop_last=True)\n",
    "    \n",
    "    train_times = list()\n",
    "    train_accs, test_accs, forget_accs = list(), list(), list()\n",
    "    \n",
    "    for epoch in range(EPOCHS):    \n",
    "        \n",
    "        # train\n",
    "        \n",
    "        train_time = 0\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for x, y in forget_loader:\n",
    "\n",
    "            output = M_unlearned(x.cuda())\n",
    "            y = y.cuda()\n",
    "            loss = error(output, y)\n",
    "            \n",
    "            # https://github.com/cleverhans-lab/unrolling-sgd/blob/main/Unlearning/finetune.py#L163\n",
    "            loss.backward(retain_graph=True)\n",
    "            grads = torch.autograd.grad(loss, [param for param in M_unlearned.parameters()], create_graph = True)\n",
    "            \n",
    "            old_params = {}\n",
    "            for i, (name, params) in enumerate(M.named_parameters()):\n",
    "                    old_params[name] = params.clone()\n",
    "                    old_params[name] += LR * grads[i]\n",
    "            for name, params in M_unlearned.named_parameters():\n",
    "                    params.data.copy_(old_params[name])\n",
    "            \n",
    "            train_time += time.time() - start_time\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "        train_times.append(train_time)\n",
    "        \n",
    "        # test\n",
    "            \n",
    "        M_unlearned.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            #\n",
    "            \n",
    "            x, y = train_set.tensors\n",
    "            \n",
    "            accs = list()\n",
    "            \n",
    "            for i in range(0, x.shape[0], BATCH_SIZE):\n",
    "            \n",
    "                output = M_unlearned(x[i:i+BATCH_SIZE].cuda())\n",
    "\n",
    "                predicted = torch.argmax(output.data, dim=-1)\n",
    "                accs.append((predicted == y[i:i+BATCH_SIZE].cuda()).float().mean().detach().cpu().numpy())\n",
    "            \n",
    "            train_accs.append(np.mean(accs))\n",
    "            \n",
    "            #\n",
    "            \n",
    "            x, y = test_set.tensors\n",
    "            \n",
    "            accs = list()\n",
    "            \n",
    "            for i in range(0, x.shape[0], BATCH_SIZE):\n",
    "            \n",
    "                output = M_unlearned(x[i:i+BATCH_SIZE].cuda())\n",
    "\n",
    "                predicted = torch.argmax(output.data, dim=-1)\n",
    "                accs.append((predicted == y[i:i+BATCH_SIZE].cuda()).float().mean().detach().cpu().numpy())\n",
    "            \n",
    "            test_accs.append(np.mean(accs))\n",
    "            \n",
    "            #\n",
    "\n",
    "            x, y = forget_set.tensors\n",
    "\n",
    "            for i in range(0, x.shape[0], BATCH_SIZE):\n",
    "\n",
    "                output = M_unlearned(x[i:i+BATCH_SIZE].cuda())\n",
    "\n",
    "                predicted = torch.argmax(output.data, dim=-1)\n",
    "                accs.append((predicted == y[i:i+BATCH_SIZE].cuda()).float().mean().detach().cpu().numpy())\n",
    "\n",
    "            forget_accs.append(np.mean(accs))\n",
    "        \n",
    "        # save\n",
    "        torch.save(M_unlearned.state_dict(), os.path.join(save_dir, f'{(epoch+1):03d}.pt'))\n",
    "\n",
    "    return train_times, train_accs, test_accs, forget_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f92ac6b-f76c-4dde-ba0a-915d5ba15b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/cleverhans-lab/unrolling-sgd/blob/main/Unlearning/finetune.py#L49\n",
    "LR = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a81ffe7-8712-4760-b4bf-072e4d26535a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd5c98208074005a7998f8c5b5eb20f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = list()\n",
    "\n",
    "for percentage in tqdm(PERCENTAGES):\n",
    "    \n",
    "    model = CNN().cuda()\n",
    "    \n",
    "    model.load_state_dict(torch.load('./weights/original/005.pt'))\n",
    "    \n",
    "    train_set, test_set, forget_set = load_deleted_dataset(DATA_DIR, percentage)\n",
    "    \n",
    "    train_times, train_accs, test_accs, forget_accs = fit(model, f'weights/unrolling-sgd/finetune/{percentage}', train_set, test_set, forget_set)\n",
    "    \n",
    "    df = pd.DataFrame(zip(train_times, train_accs, test_accs, forget_accs), columns=['train_time', 'train_acc', 'test_acc', 'forget_acc'])\n",
    "    df['epoch'] = range(1, EPOCHS+1)\n",
    "    df['percentage'] = percentage\n",
    "    \n",
    "    results.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f09bcabd-676b-4172-ad65-1ba2117bd35c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>train_time</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>forget_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage</th>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.093071</td>\n",
       "      <td>0.098697</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.097892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.142839</td>\n",
       "      <td>0.098697</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.097892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.106299</td>\n",
       "      <td>0.098697</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.097892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.107764</td>\n",
       "      <td>0.098697</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.097892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.107549</td>\n",
       "      <td>0.098697</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.097892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">10</th>\n",
       "      <th>1</th>\n",
       "      <td>1.582503</td>\n",
       "      <td>0.098711</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.691955</td>\n",
       "      <td>0.098711</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.651448</td>\n",
       "      <td>0.098711</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.670228</td>\n",
       "      <td>0.098711</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.899124</td>\n",
       "      <td>0.098711</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20</th>\n",
       "      <th>1</th>\n",
       "      <td>3.626478</td>\n",
       "      <td>0.098271</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.099337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.527236</td>\n",
       "      <td>0.098271</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.099337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.505100</td>\n",
       "      <td>0.098271</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.099337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.649031</td>\n",
       "      <td>0.098271</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.099337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.531990</td>\n",
       "      <td>0.098271</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.099337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">30</th>\n",
       "      <th>1</th>\n",
       "      <td>5.671814</td>\n",
       "      <td>0.098558</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.671598</td>\n",
       "      <td>0.098558</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.404320</td>\n",
       "      <td>0.098558</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.204876</td>\n",
       "      <td>0.098558</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.338945</td>\n",
       "      <td>0.098558</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">40</th>\n",
       "      <th>1</th>\n",
       "      <td>7.446170</td>\n",
       "      <td>0.098389</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.079574</td>\n",
       "      <td>0.098389</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.060263</td>\n",
       "      <td>0.098389</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.006691</td>\n",
       "      <td>0.098389</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.947205</td>\n",
       "      <td>0.098389</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">50</th>\n",
       "      <th>1</th>\n",
       "      <td>9.374218</td>\n",
       "      <td>0.098714</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.908031</td>\n",
       "      <td>0.098714</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.111207</td>\n",
       "      <td>0.098714</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.902072</td>\n",
       "      <td>0.098714</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.005178</td>\n",
       "      <td>0.098714</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">60</th>\n",
       "      <th>1</th>\n",
       "      <td>11.377407</td>\n",
       "      <td>0.099542</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.725685</td>\n",
       "      <td>0.099542</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.559859</td>\n",
       "      <td>0.099542</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.709129</td>\n",
       "      <td>0.099542</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.657964</td>\n",
       "      <td>0.099542</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">70</th>\n",
       "      <th>1</th>\n",
       "      <td>13.166406</td>\n",
       "      <td>0.098857</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.421486</td>\n",
       "      <td>0.098857</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.464874</td>\n",
       "      <td>0.098857</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.200490</td>\n",
       "      <td>0.098857</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.027715</td>\n",
       "      <td>0.098857</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">80</th>\n",
       "      <th>1</th>\n",
       "      <td>15.167992</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.071881</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.064431</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.120578</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.100672</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">90</th>\n",
       "      <th>1</th>\n",
       "      <td>16.934073</td>\n",
       "      <td>0.097739</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.744517</td>\n",
       "      <td>0.097739</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.703261</td>\n",
       "      <td>0.097739</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.000236</td>\n",
       "      <td>0.097739</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.107888</td>\n",
       "      <td>0.097739</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">99</th>\n",
       "      <th>1</th>\n",
       "      <td>19.186974</td>\n",
       "      <td>0.095943</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.958012</td>\n",
       "      <td>0.095943</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.719515</td>\n",
       "      <td>0.095943</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.192384</td>\n",
       "      <td>0.095943</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.826000</td>\n",
       "      <td>0.095943</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  train_time  train_acc  test_acc  forget_acc\n",
       "percentage epoch                                             \n",
       "1          1        0.093071   0.098697  0.097943    0.097892\n",
       "           2        0.142839   0.098697  0.097943    0.097892\n",
       "           3        0.106299   0.098697  0.097943    0.097892\n",
       "           4        0.107764   0.098697  0.097943    0.097892\n",
       "           5        0.107549   0.098697  0.097943    0.097892\n",
       "10         1        1.582503   0.098711  0.097943    0.098116\n",
       "           2        1.691955   0.098711  0.097943    0.098116\n",
       "           3        1.651448   0.098711  0.097943    0.098116\n",
       "           4        1.670228   0.098711  0.097943    0.098116\n",
       "           5        1.899124   0.098711  0.097943    0.098116\n",
       "20         1        3.626478   0.098271  0.097943    0.099337\n",
       "           2        3.527236   0.098271  0.097943    0.099337\n",
       "           3        3.505100   0.098271  0.097943    0.099337\n",
       "           4        3.649031   0.098271  0.097943    0.099337\n",
       "           5        3.531990   0.098271  0.097943    0.099337\n",
       "30         1        5.671814   0.098558  0.097943    0.098637\n",
       "           2        5.671598   0.098558  0.097943    0.098637\n",
       "           3        5.404320   0.098558  0.097943    0.098637\n",
       "           4        5.204876   0.098558  0.097943    0.098637\n",
       "           5        5.338945   0.098558  0.097943    0.098637\n",
       "40         1        7.446170   0.098389  0.097943    0.098836\n",
       "           2        7.079574   0.098389  0.097943    0.098836\n",
       "           3        7.060263   0.098389  0.097943    0.098836\n",
       "           4        7.006691   0.098389  0.097943    0.098836\n",
       "           5        6.947205   0.098389  0.097943    0.098836\n",
       "50         1        9.374218   0.098714  0.097943    0.098521\n",
       "           2        8.908031   0.098714  0.097943    0.098521\n",
       "           3        9.111207   0.098714  0.097943    0.098521\n",
       "           4        8.902072   0.098714  0.097943    0.098521\n",
       "           5        9.005178   0.098714  0.097943    0.098521\n",
       "60         1       11.377407   0.099542  0.097943    0.098118\n",
       "           2       10.725685   0.099542  0.097943    0.098118\n",
       "           3       10.559859   0.099542  0.097943    0.098118\n",
       "           4       10.709129   0.099542  0.097943    0.098118\n",
       "           5       10.657964   0.099542  0.097943    0.098118\n",
       "70         1       13.166406   0.098857  0.097943    0.098536\n",
       "           2       12.421486   0.098857  0.097943    0.098536\n",
       "           3       12.464874   0.098857  0.097943    0.098536\n",
       "           4       12.200490   0.098857  0.097943    0.098536\n",
       "           5       12.027715   0.098857  0.097943    0.098536\n",
       "80         1       15.167992   0.099500  0.097943    0.098421\n",
       "           2       14.071881   0.099500  0.097943    0.098421\n",
       "           3       14.064431   0.099500  0.097943    0.098421\n",
       "           4       14.120578   0.099500  0.097943    0.098421\n",
       "           5       14.100672   0.099500  0.097943    0.098421\n",
       "90         1       16.934073   0.097739  0.097943    0.098669\n",
       "           2       15.744517   0.097739  0.097943    0.098669\n",
       "           3       15.703261   0.097739  0.097943    0.098669\n",
       "           4       16.000236   0.097739  0.097943    0.098669\n",
       "           5       16.107888   0.097739  0.097943    0.098669\n",
       "99         1       19.186974   0.095943  0.097943    0.098589\n",
       "           2       17.958012   0.095943  0.097943    0.098589\n",
       "           3       17.719515   0.095943  0.097943    0.098589\n",
       "           4       18.192384   0.095943  0.097943    0.098589\n",
       "           5       17.826000   0.095943  0.097943    0.098589"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.concat(results).set_index(['percentage', 'epoch'])\n",
    "\n",
    "results.to_csv('results/unrolling-sgd/finetune.csv')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1186c623-c225-4167-945e-9f9239d0f59a",
   "metadata": {},
   "source": [
    "# correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a47633c-9ee2-4e99-90f1-0c52b74f0016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_loss(x, y):\n",
    "    log_prob = -1.0 * F.log_softmax(x, 1)\n",
    "    loss = log_prob.gather(1, y.unsqueeze(1))\n",
    "    loss = loss.mean()\n",
    "    avg_std = torch.sum(torch.std(x, dim=1))/(len(x.view(-1)))\n",
    "    loss = loss + STD_REG*avg_std\n",
    "    return loss\n",
    "\n",
    "def my_cross_entropy(x, y):\n",
    "    log_prob = -1.0 * F.log_softmax(x, 1)\n",
    "    loss = log_prob.gather(1, y.unsqueeze(1))\n",
    "    loss = loss.mean()\n",
    "\n",
    "    #x is (N,C)\n",
    "    N,C = x.shape\n",
    "    p = F.softmax(x,1)\n",
    "    hessian_loss = torch.sum(p *(1-p),dim =1)\n",
    "    hessian_loss = hessian_loss.mean()\n",
    "\n",
    "    loss = loss + STD_REG * hessian_loss\n",
    "    return loss\n",
    "\n",
    "# https://github.com/cleverhans-lab/unrolling-sgd/blob/main/Unlearning/Correlation_unlearning.py#L130\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9368b9e-4fdf-47ee-bb07-dae3d7e6512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, save_dir, train_set, test_set, forget_set):\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # https://github.com/cleverhans-lab/unrolling-sgd/blob/main/Unlearning/Correlation_unlearning.py#L161\n",
    "\n",
    "    M = copy.deepcopy(model)\n",
    "\n",
    "    M.train()\n",
    "    \n",
    "    # https://github.com/cleverhans-lab/unrolling-sgd/blob/main/Unlearning/Correlation_unlearning.py#L172\n",
    "    optimizer = torch.optim.SGD(M.parameters(), lr=LR, weight_decay = L2)\n",
    "    \n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True, drop_last=True)\n",
    "    \n",
    "    forget_loader = torch.utils.data.DataLoader(forget_set, batch_size = BATCH_SIZE, shuffle = True, drop_last=True)\n",
    "    \n",
    "    train_times = list()\n",
    "    train_accs, test_accs, forget_accs = list(), list(), list()\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        # train\n",
    "        \n",
    "        train_time = 0\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # https://github.com/cleverhans-lab/unrolling-sgd/blob/main/Unlearning/Correlation_unlearning.py#L200\n",
    "        \n",
    "        # only update M:\n",
    "        \n",
    "        M.train()\n",
    "        \n",
    "        for x, y in forget_loader:\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs_M = M(x.cuda())\n",
    "            \n",
    "            targets = y.cuda()\n",
    "        \n",
    "            if LOSS_FUNC == 'hess':\n",
    "                loss_M = my_cross_entropy(outputs_M, targets)\n",
    "            if LOSS_FUNC =='std':\n",
    "                loss_M = std_loss(outputs_M, targets)\n",
    "            if LOSS_FUNC =='regular':\n",
    "                loss_M = loss_fn(outputs_M, targets)\n",
    "                \n",
    "            loss_M.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # now we also want to compute the gradient:\n",
    "        \n",
    "        grad_list = []\n",
    "        \n",
    "        for x, y in train_loader:\n",
    "\n",
    "            output_grad = M(x.cuda())\n",
    "            \n",
    "            label = y.cuda()\n",
    "            \n",
    "            if LOSS_FUNC == 'hess':\n",
    "                loss_grad = my_cross_entropy(output_grad, label)\n",
    "            if LOSS_FUNC =='std':\n",
    "                loss_grad = std_loss(output_grad, label)\n",
    "            if LOSS_FUNC =='regular':\n",
    "                loss_grad = loss_fn(output_grad, label)\n",
    "            \n",
    "            loss_grad.backward(retain_graph=True)\n",
    "            grads = torch.autograd.grad(loss_grad, [param for param in M.parameters()], create_graph = True)\n",
    "            # !!! modified !!! original code cause OOM\n",
    "            # grad_list.append(grads)\n",
    "            grad_list.append([i.detach().cpu() for i in grads])\n",
    "        \n",
    "        # https://github.com/cleverhans-lab/unrolling-sgd/blob/main/Unlearning/Correlation_unlearning.py#L227\n",
    "            \n",
    "        # update both M and M'\n",
    "        \n",
    "        for x, y in forget_loader:\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs_M = M(x.cuda())\n",
    "            \n",
    "            targets = y.cuda()\n",
    "        \n",
    "            if LOSS_FUNC == 'hess':\n",
    "                loss_M = my_cross_entropy(outputs_M, targets)\n",
    "            if LOSS_FUNC =='std':\n",
    "                loss_M = std_loss(outputs_M, targets)\n",
    "            if LOSS_FUNC =='regular':\n",
    "                loss_M = loss_fn(outputs_M, targets)\n",
    "                \n",
    "            loss_M.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # Now, get M''_(N+t)\n",
    "            \n",
    "        # https://github.com/cleverhans-lab/unrolling-sgd/blob/main/Unlearning/Correlation_unlearning.py#L270\n",
    "        \n",
    "        M_unlearned = copy.deepcopy(M)\n",
    "        \n",
    "        old_params = {}\n",
    "        for i, (name, params) in enumerate(M.named_parameters()):\n",
    "            old_params[name] = params.clone()\n",
    "            for grads in grad_list:\n",
    "                old_params[name] += LR * grads[i].cuda()\n",
    "        for name, params in M_unlearned.named_parameters():\n",
    "            params.data.copy_(old_params[name])\n",
    "        \n",
    "            \n",
    "        train_time += time.time() - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "            \n",
    "        train_times.append(train_time)\n",
    "        \n",
    "        # test\n",
    "            \n",
    "        M_unlearned.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            #\n",
    "            \n",
    "            x, y = train_set.tensors\n",
    "            \n",
    "            accs = list()\n",
    "            \n",
    "            for i in range(0, x.shape[0], BATCH_SIZE):\n",
    "            \n",
    "                output = M_unlearned(x[i:i+BATCH_SIZE].cuda())\n",
    "\n",
    "                predicted = torch.argmax(output.data, dim=-1)\n",
    "                accs.append((predicted == y[i:i+BATCH_SIZE].cuda()).float().mean().detach().cpu().numpy())\n",
    "            \n",
    "            train_accs.append(np.mean(accs))\n",
    "            \n",
    "            #\n",
    "            \n",
    "            x, y = test_set.tensors\n",
    "            \n",
    "            accs = list()\n",
    "            \n",
    "            for i in range(0, x.shape[0], BATCH_SIZE):\n",
    "            \n",
    "                output = M_unlearned(x[i:i+BATCH_SIZE].cuda())\n",
    "\n",
    "                predicted = torch.argmax(output.data, dim=-1)\n",
    "                accs.append((predicted == y[i:i+BATCH_SIZE].cuda()).float().mean().detach().cpu().numpy())\n",
    "            \n",
    "            test_accs.append(np.mean(accs))\n",
    "            \n",
    "            #\n",
    "\n",
    "            x, y = forget_set.tensors\n",
    "\n",
    "            for i in range(0, x.shape[0], BATCH_SIZE):\n",
    "\n",
    "                output = M_unlearned(x[i:i+BATCH_SIZE].cuda())\n",
    "\n",
    "                predicted = torch.argmax(output.data, dim=-1)\n",
    "                accs.append((predicted == y[i:i+BATCH_SIZE].cuda()).float().mean().detach().cpu().numpy())\n",
    "\n",
    "            forget_accs.append(np.mean(accs))\n",
    "        \n",
    "        # save\n",
    "        torch.save(M_unlearned.state_dict(), os.path.join(save_dir, f'{(epoch+1):03d}.pt'))\n",
    "\n",
    "    return train_times, train_accs, test_accs, forget_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a42f9c3-e935-41dd-bf63-d572fb99d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/cleverhans-lab/unrolling-sgd/blob/main/Unlearning/Correlation_unlearning.py#L167\n",
    "LR = 0.01\n",
    "# https://github.com/cleverhans-lab/unrolling-sgd/blob/main/Unlearning/Correlation_unlearning.py#L72\n",
    "L2 = 0.\n",
    "# https://github.com/cleverhans-lab/unrolling-sgd/blob/main/Unlearning/Correlation_unlearning.py#L71\n",
    "STD_REG = 0.\n",
    "\n",
    "LOSS_FUNC = 'hess'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36189566-41a1-4eb2-b3f4-0a7ebf231ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbe2462406b4cc4afa11f8493b259dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = list()\n",
    "\n",
    "for percentage in tqdm(PERCENTAGES):\n",
    "    \n",
    "    model = CNN().cuda()\n",
    "    \n",
    "    model.load_state_dict(torch.load('./weights/original/005.pt'))\n",
    "    \n",
    "    train_set, test_set, forget_set = load_deleted_dataset(DATA_DIR, percentage)\n",
    "    \n",
    "    train_times, train_accs, test_accs, forget_accs = fit(model, f'weights/unrolling-sgd/correlation/{percentage}', train_set, test_set, forget_set)\n",
    "    \n",
    "    df = pd.DataFrame(zip(train_times, train_accs, test_accs, forget_accs), columns=['train_time', 'train_acc', 'test_acc', 'forget_acc'])\n",
    "    df['epoch'] = range(1, EPOCHS+1)\n",
    "    df['percentage'] = percentage\n",
    "    \n",
    "    results.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "692050cf-af0b-40f9-b6fb-428f4fa77855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>train_time</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>forget_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage</th>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>23.489917</td>\n",
       "      <td>0.048499</td>\n",
       "      <td>0.048123</td>\n",
       "      <td>0.049354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.695684</td>\n",
       "      <td>0.092151</td>\n",
       "      <td>0.096146</td>\n",
       "      <td>0.096260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.668467</td>\n",
       "      <td>0.103847</td>\n",
       "      <td>0.106430</td>\n",
       "      <td>0.106771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.274964</td>\n",
       "      <td>0.099068</td>\n",
       "      <td>0.100839</td>\n",
       "      <td>0.101311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.788038</td>\n",
       "      <td>0.112177</td>\n",
       "      <td>0.113518</td>\n",
       "      <td>0.114521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">10</th>\n",
       "      <th>1</th>\n",
       "      <td>21.201748</td>\n",
       "      <td>0.096694</td>\n",
       "      <td>0.098243</td>\n",
       "      <td>0.100299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.727305</td>\n",
       "      <td>0.090640</td>\n",
       "      <td>0.088658</td>\n",
       "      <td>0.087512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.535512</td>\n",
       "      <td>0.102007</td>\n",
       "      <td>0.103934</td>\n",
       "      <td>0.105851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.748307</td>\n",
       "      <td>0.112411</td>\n",
       "      <td>0.113518</td>\n",
       "      <td>0.112837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.600991</td>\n",
       "      <td>0.172912</td>\n",
       "      <td>0.173223</td>\n",
       "      <td>0.170721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20</th>\n",
       "      <th>1</th>\n",
       "      <td>21.533739</td>\n",
       "      <td>0.098417</td>\n",
       "      <td>0.097344</td>\n",
       "      <td>0.095476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.860074</td>\n",
       "      <td>0.099688</td>\n",
       "      <td>0.097843</td>\n",
       "      <td>0.095930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.119174</td>\n",
       "      <td>0.098396</td>\n",
       "      <td>0.095946</td>\n",
       "      <td>0.098610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.203216</td>\n",
       "      <td>0.141708</td>\n",
       "      <td>0.143171</td>\n",
       "      <td>0.139172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.255934</td>\n",
       "      <td>0.129937</td>\n",
       "      <td>0.133886</td>\n",
       "      <td>0.128725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">30</th>\n",
       "      <th>1</th>\n",
       "      <td>22.104795</td>\n",
       "      <td>0.101128</td>\n",
       "      <td>0.101038</td>\n",
       "      <td>0.103382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.353467</td>\n",
       "      <td>0.111696</td>\n",
       "      <td>0.113518</td>\n",
       "      <td>0.113799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.309126</td>\n",
       "      <td>0.208754</td>\n",
       "      <td>0.210763</td>\n",
       "      <td>0.210866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.712210</td>\n",
       "      <td>0.101128</td>\n",
       "      <td>0.101038</td>\n",
       "      <td>0.103382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.500949</td>\n",
       "      <td>0.162676</td>\n",
       "      <td>0.167033</td>\n",
       "      <td>0.158355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">40</th>\n",
       "      <th>1</th>\n",
       "      <td>22.534714</td>\n",
       "      <td>0.054222</td>\n",
       "      <td>0.054413</td>\n",
       "      <td>0.052828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.704143</td>\n",
       "      <td>0.218028</td>\n",
       "      <td>0.213958</td>\n",
       "      <td>0.211518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.819202</td>\n",
       "      <td>0.135972</td>\n",
       "      <td>0.128994</td>\n",
       "      <td>0.134819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.424061</td>\n",
       "      <td>0.197167</td>\n",
       "      <td>0.191494</td>\n",
       "      <td>0.193938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.091496</td>\n",
       "      <td>0.232028</td>\n",
       "      <td>0.232927</td>\n",
       "      <td>0.227011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">50</th>\n",
       "      <th>1</th>\n",
       "      <td>23.031690</td>\n",
       "      <td>0.042044</td>\n",
       "      <td>0.039936</td>\n",
       "      <td>0.041017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.550739</td>\n",
       "      <td>0.112673</td>\n",
       "      <td>0.116813</td>\n",
       "      <td>0.116132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.665971</td>\n",
       "      <td>0.129398</td>\n",
       "      <td>0.131290</td>\n",
       "      <td>0.128947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.195868</td>\n",
       "      <td>0.102312</td>\n",
       "      <td>0.105831</td>\n",
       "      <td>0.101419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24.468297</td>\n",
       "      <td>0.243104</td>\n",
       "      <td>0.252396</td>\n",
       "      <td>0.246278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">60</th>\n",
       "      <th>1</th>\n",
       "      <td>23.054505</td>\n",
       "      <td>0.236250</td>\n",
       "      <td>0.248003</td>\n",
       "      <td>0.245697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.687860</td>\n",
       "      <td>0.100250</td>\n",
       "      <td>0.100040</td>\n",
       "      <td>0.098444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.533322</td>\n",
       "      <td>0.107917</td>\n",
       "      <td>0.108726</td>\n",
       "      <td>0.105463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.395105</td>\n",
       "      <td>0.263792</td>\n",
       "      <td>0.264876</td>\n",
       "      <td>0.265994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.916171</td>\n",
       "      <td>0.156417</td>\n",
       "      <td>0.165136</td>\n",
       "      <td>0.162400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">70</th>\n",
       "      <th>1</th>\n",
       "      <td>23.644594</td>\n",
       "      <td>0.125111</td>\n",
       "      <td>0.121306</td>\n",
       "      <td>0.122905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.038399</td>\n",
       "      <td>0.197935</td>\n",
       "      <td>0.195887</td>\n",
       "      <td>0.192170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.608619</td>\n",
       "      <td>0.102964</td>\n",
       "      <td>0.103335</td>\n",
       "      <td>0.100669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.982249</td>\n",
       "      <td>0.342917</td>\n",
       "      <td>0.355132</td>\n",
       "      <td>0.347978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.797917</td>\n",
       "      <td>0.088921</td>\n",
       "      <td>0.091354</td>\n",
       "      <td>0.091271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">80</th>\n",
       "      <th>1</th>\n",
       "      <td>24.573494</td>\n",
       "      <td>0.099833</td>\n",
       "      <td>0.097344</td>\n",
       "      <td>0.097008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.447432</td>\n",
       "      <td>0.269500</td>\n",
       "      <td>0.276058</td>\n",
       "      <td>0.271322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.575164</td>\n",
       "      <td>0.471250</td>\n",
       "      <td>0.491414</td>\n",
       "      <td>0.485814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.314490</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.166833</td>\n",
       "      <td>0.165058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.083449</td>\n",
       "      <td>0.408917</td>\n",
       "      <td>0.407149</td>\n",
       "      <td>0.410145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">90</th>\n",
       "      <th>1</th>\n",
       "      <td>25.331308</td>\n",
       "      <td>0.179189</td>\n",
       "      <td>0.193690</td>\n",
       "      <td>0.187031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.100163</td>\n",
       "      <td>0.394781</td>\n",
       "      <td>0.394469</td>\n",
       "      <td>0.391945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.448052</td>\n",
       "      <td>0.360040</td>\n",
       "      <td>0.350739</td>\n",
       "      <td>0.351512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.866441</td>\n",
       "      <td>0.396775</td>\n",
       "      <td>0.389377</td>\n",
       "      <td>0.384402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26.011507</td>\n",
       "      <td>0.785239</td>\n",
       "      <td>0.788538</td>\n",
       "      <td>0.784483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">99</th>\n",
       "      <th>1</th>\n",
       "      <td>26.465792</td>\n",
       "      <td>0.957237</td>\n",
       "      <td>0.965555</td>\n",
       "      <td>0.967540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.611852</td>\n",
       "      <td>0.978618</td>\n",
       "      <td>0.985923</td>\n",
       "      <td>0.986838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.715510</td>\n",
       "      <td>0.970395</td>\n",
       "      <td>0.982228</td>\n",
       "      <td>0.983813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.242393</td>\n",
       "      <td>0.976974</td>\n",
       "      <td>0.985024</td>\n",
       "      <td>0.984807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.511864</td>\n",
       "      <td>0.985197</td>\n",
       "      <td>0.986921</td>\n",
       "      <td>0.988623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  train_time  train_acc  test_acc  forget_acc\n",
       "percentage epoch                                             \n",
       "1          1       23.489917   0.048499  0.048123    0.049354\n",
       "           2       21.695684   0.092151  0.096146    0.096260\n",
       "           3       21.668467   0.103847  0.106430    0.106771\n",
       "           4       22.274964   0.099068  0.100839    0.101311\n",
       "           5       21.788038   0.112177  0.113518    0.114521\n",
       "10         1       21.201748   0.096694  0.098243    0.100299\n",
       "           2       21.727305   0.090640  0.088658    0.087512\n",
       "           3       21.535512   0.102007  0.103934    0.105851\n",
       "           4       21.748307   0.112411  0.113518    0.112837\n",
       "           5       21.600991   0.172912  0.173223    0.170721\n",
       "20         1       21.533739   0.098417  0.097344    0.095476\n",
       "           2       21.860074   0.099688  0.097843    0.095930\n",
       "           3       22.119174   0.098396  0.095946    0.098610\n",
       "           4       22.203216   0.141708  0.143171    0.139172\n",
       "           5       22.255934   0.129937  0.133886    0.128725\n",
       "30         1       22.104795   0.101128  0.101038    0.103382\n",
       "           2       22.353467   0.111696  0.113518    0.113799\n",
       "           3       22.309126   0.208754  0.210763    0.210866\n",
       "           4       23.712210   0.101128  0.101038    0.103382\n",
       "           5       22.500949   0.162676  0.167033    0.158355\n",
       "40         1       22.534714   0.054222  0.054413    0.052828\n",
       "           2       22.704143   0.218028  0.213958    0.211518\n",
       "           3       22.819202   0.135972  0.128994    0.134819\n",
       "           4       23.424061   0.197167  0.191494    0.193938\n",
       "           5       23.091496   0.232028  0.232927    0.227011\n",
       "50         1       23.031690   0.042044  0.039936    0.041017\n",
       "           2       23.550739   0.112673  0.116813    0.116132\n",
       "           3       23.665971   0.129398  0.131290    0.128947\n",
       "           4       25.195868   0.102312  0.105831    0.101419\n",
       "           5       24.468297   0.243104  0.252396    0.246278\n",
       "60         1       23.054505   0.236250  0.248003    0.245697\n",
       "           2       23.687860   0.100250  0.100040    0.098444\n",
       "           3       23.533322   0.107917  0.108726    0.105463\n",
       "           4       23.395105   0.263792  0.264876    0.265994\n",
       "           5       23.916171   0.156417  0.165136    0.162400\n",
       "70         1       23.644594   0.125111  0.121306    0.122905\n",
       "           2       24.038399   0.197935  0.195887    0.192170\n",
       "           3       24.608619   0.102964  0.103335    0.100669\n",
       "           4       24.982249   0.342917  0.355132    0.347978\n",
       "           5       23.797917   0.088921  0.091354    0.091271\n",
       "80         1       24.573494   0.099833  0.097344    0.097008\n",
       "           2       24.447432   0.269500  0.276058    0.271322\n",
       "           3       25.575164   0.471250  0.491414    0.485814\n",
       "           4       25.314490   0.162500  0.166833    0.165058\n",
       "           5       25.083449   0.408917  0.407149    0.410145\n",
       "90         1       25.331308   0.179189  0.193690    0.187031\n",
       "           2       25.100163   0.394781  0.394469    0.391945\n",
       "           3       24.448052   0.360040  0.350739    0.351512\n",
       "           4       24.866441   0.396775  0.389377    0.384402\n",
       "           5       26.011507   0.785239  0.788538    0.784483\n",
       "99         1       26.465792   0.957237  0.965555    0.967540\n",
       "           2       25.611852   0.978618  0.985923    0.986838\n",
       "           3       25.715510   0.970395  0.982228    0.983813\n",
       "           4       26.242393   0.976974  0.985024    0.984807\n",
       "           5       25.511864   0.985197  0.986921    0.988623"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.concat(results).set_index(['percentage', 'epoch'])\n",
    "\n",
    "results.to_csv('results/unrolling-sgd/correlation.csv')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be47c336-f4e4-47b6-b813-bdea8d18d1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
