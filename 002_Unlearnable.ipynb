{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbae74ae-2cd5-4cd7-9a33-9f8ec2117853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "403b3846-9d50-4090-bde4-0409bd6df012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_original_dataset, load_deleted_dataset\n",
    "from models import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f070e1c-cde4-44db-8533-1aa4e940cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'Datasets/Features/'\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "PERCENTAGES = [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adc832b8-a9ba-4e86-8054-83c68fd4f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('./libraries/Unlearnable-Examples/'))\n",
    "import toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "babdf70c-98e0-4d26-b3db-93a14227a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/HanxunH/Unlearnable-Examples/blob/main/perturbation.py#L45\n",
    "\n",
    "EPSILON = 8\n",
    "NUM_STEPS = 1\n",
    "STEP_SIZE = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7170876-46e4-49b0-ac7a-e4cbedeb0726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/HanxunH/Unlearnable-Examples/blob/main/perturbation.py#L51\n",
    "# https://github.com/HanxunH/Unlearnable-Examples/blob/main/perturbation.py#L446\n",
    "\n",
    "noise_generator = toolbox.PerturbationTool(\n",
    "    epsilon=EPSILON / 255,\n",
    "    num_steps=NUM_STEPS,\n",
    "    step_size=STEP_SIZE / 255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b25b5-7572-4d3f-a999-78db6c9c4ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_random_noise(x):\n",
    "    \n",
    "    # https://github.com/HanxunH/Unlearnable-Examples/blob/main/dataset.py#L441\n",
    "    noise = noise_generator.random_noise(noise_shape=x.shape)\n",
    "    \n",
    "    # https://github.com/HanxunH/Unlearnable-Examples/blob/main/dataset.py#L448\n",
    "    noise = noise.mul(255).clamp_(0, 255)\n",
    "    \n",
    "    # https://github.com/HanxunH/Unlearnable-Examples/blob/main/perturbation.py#L451\n",
    "    x = x + noise.to(x.device)\n",
    "    x = torch.clamp(x, 0, 255)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c13a2159-60c2-4395-bb31-0fd7028ae9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, save_dir, train_set, test_set, forget_set):\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    train_x, train_y = train_set.tensors\n",
    "    forget_x, forget_y = forget_set.tensors\n",
    "    \n",
    "    forget_x = add_random_noise(forget_x)\n",
    "    \n",
    "    train_set = torch.utils.data.TensorDataset(\n",
    "        torch.concat([train_x, forget_x], dim=0), \n",
    "        torch.concat([train_y, forget_y], dim=0), \n",
    "    )\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    error = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True, drop_last=True)\n",
    "    \n",
    "    train_times = list()\n",
    "    train_accs, test_accs, forget_accs = list(), list(), list()\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        # train\n",
    "        \n",
    "        accs = list()\n",
    "        \n",
    "        train_time = 0\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x.cuda())\n",
    "            y = y.cuda()\n",
    "            loss = error(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_time += time.time() - start_time\n",
    "            \n",
    "            predicted = torch.argmax(output.data, dim=-1)\n",
    "            accs.append((predicted == y).float().mean().detach().cpu().numpy())\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "        train_times.append(train_time)\n",
    "        train_accs.append(np.mean(accs))\n",
    "        \n",
    "        # test\n",
    "            \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            x, y = test_set.tensors\n",
    "            \n",
    "            accs = list()\n",
    "            \n",
    "            for i in range(0, x.shape[0], BATCH_SIZE):\n",
    "            \n",
    "                output = model(x[i:i+BATCH_SIZE].cuda())\n",
    "\n",
    "                predicted = torch.argmax(output.data, dim=-1)\n",
    "                accs.append((predicted == y[i:i+BATCH_SIZE].cuda()).float().mean().detach().cpu().numpy())\n",
    "            \n",
    "            test_accs.append(np.mean(accs))\n",
    "            \n",
    "\n",
    "            x, y = forget_set.tensors\n",
    "\n",
    "            for i in range(0, x.shape[0], BATCH_SIZE):\n",
    "\n",
    "                output = model(x[i:i+BATCH_SIZE].cuda())\n",
    "\n",
    "                predicted = torch.argmax(output.data, dim=-1)\n",
    "                accs.append((predicted == y[i:i+BATCH_SIZE].cuda()).float().mean().detach().cpu().numpy())\n",
    "\n",
    "            forget_accs.append(np.mean(accs))\n",
    "        \n",
    "        # save\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, f'{(epoch+1):03d}.pt'))\n",
    "\n",
    "    return train_times, train_accs, test_accs, forget_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f93ce0-4df5-41fe-ab4d-aef8c750ad58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce560d5a4b5a4addae053f9a0217de02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = list()\n",
    "\n",
    "for percentage in tqdm(PERCENTAGES):\n",
    "    \n",
    "    model = CNN().cuda()\n",
    "    \n",
    "    train_set, test_set, forget_set = load_deleted_dataset(DATA_DIR, percentage)\n",
    "    \n",
    "    train_times, train_accs, test_accs, forget_accs = fit(model, f'weights/Unlearnable/{percentage}', train_set, test_set, forget_set)\n",
    "    \n",
    "    df = pd.DataFrame(zip(train_times, train_accs, test_accs, forget_accs), columns=['train_time', 'train_acc', 'test_acc', 'forget_acc'])\n",
    "    df['epoch'] = range(1, EPOCHS+1)\n",
    "    df['percentage'] = percentage\n",
    "    \n",
    "    results.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1ea734a-a103-47f6-a272-6873307012d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>train_time</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>forget_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage</th>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>12.197492</td>\n",
       "      <td>0.862650</td>\n",
       "      <td>0.975739</td>\n",
       "      <td>0.975904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.109900</td>\n",
       "      <td>0.940800</td>\n",
       "      <td>0.981330</td>\n",
       "      <td>0.981457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.314586</td>\n",
       "      <td>0.948533</td>\n",
       "      <td>0.984026</td>\n",
       "      <td>0.983904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.177313</td>\n",
       "      <td>0.954917</td>\n",
       "      <td>0.985523</td>\n",
       "      <td>0.985599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.217436</td>\n",
       "      <td>0.958850</td>\n",
       "      <td>0.985623</td>\n",
       "      <td>0.985410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">10</th>\n",
       "      <th>1</th>\n",
       "      <td>9.943733</td>\n",
       "      <td>0.867033</td>\n",
       "      <td>0.978934</td>\n",
       "      <td>0.979042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.187575</td>\n",
       "      <td>0.946133</td>\n",
       "      <td>0.981729</td>\n",
       "      <td>0.982036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.533017</td>\n",
       "      <td>0.949667</td>\n",
       "      <td>0.985224</td>\n",
       "      <td>0.984780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.228199</td>\n",
       "      <td>0.953500</td>\n",
       "      <td>0.986422</td>\n",
       "      <td>0.986589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.616878</td>\n",
       "      <td>0.956467</td>\n",
       "      <td>0.986022</td>\n",
       "      <td>0.986776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20</th>\n",
       "      <th>1</th>\n",
       "      <td>10.002365</td>\n",
       "      <td>0.874450</td>\n",
       "      <td>0.978335</td>\n",
       "      <td>0.976517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.004757</td>\n",
       "      <td>0.945867</td>\n",
       "      <td>0.982728</td>\n",
       "      <td>0.981786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.251070</td>\n",
       "      <td>0.951350</td>\n",
       "      <td>0.984325</td>\n",
       "      <td>0.984012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.223609</td>\n",
       "      <td>0.955633</td>\n",
       "      <td>0.987121</td>\n",
       "      <td>0.985374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.217983</td>\n",
       "      <td>0.958617</td>\n",
       "      <td>0.986122</td>\n",
       "      <td>0.986192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">30</th>\n",
       "      <th>1</th>\n",
       "      <td>10.159244</td>\n",
       "      <td>0.866150</td>\n",
       "      <td>0.976538</td>\n",
       "      <td>0.975385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.183870</td>\n",
       "      <td>0.941867</td>\n",
       "      <td>0.983227</td>\n",
       "      <td>0.980879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.238254</td>\n",
       "      <td>0.951067</td>\n",
       "      <td>0.982628</td>\n",
       "      <td>0.981485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.343989</td>\n",
       "      <td>0.954683</td>\n",
       "      <td>0.983427</td>\n",
       "      <td>0.984339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.358709</td>\n",
       "      <td>0.956150</td>\n",
       "      <td>0.986621</td>\n",
       "      <td>0.986765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">40</th>\n",
       "      <th>1</th>\n",
       "      <td>10.083722</td>\n",
       "      <td>0.872117</td>\n",
       "      <td>0.980731</td>\n",
       "      <td>0.979598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.389214</td>\n",
       "      <td>0.946400</td>\n",
       "      <td>0.979633</td>\n",
       "      <td>0.980303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.279586</td>\n",
       "      <td>0.952917</td>\n",
       "      <td>0.984125</td>\n",
       "      <td>0.984360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.659853</td>\n",
       "      <td>0.954900</td>\n",
       "      <td>0.983626</td>\n",
       "      <td>0.984978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.253969</td>\n",
       "      <td>0.956783</td>\n",
       "      <td>0.986821</td>\n",
       "      <td>0.987888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">50</th>\n",
       "      <th>1</th>\n",
       "      <td>9.902655</td>\n",
       "      <td>0.844583</td>\n",
       "      <td>0.976637</td>\n",
       "      <td>0.975370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.267082</td>\n",
       "      <td>0.940717</td>\n",
       "      <td>0.978934</td>\n",
       "      <td>0.977443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.229579</td>\n",
       "      <td>0.948850</td>\n",
       "      <td>0.981929</td>\n",
       "      <td>0.983064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.100196</td>\n",
       "      <td>0.951517</td>\n",
       "      <td>0.985723</td>\n",
       "      <td>0.984787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.076050</td>\n",
       "      <td>0.954100</td>\n",
       "      <td>0.986522</td>\n",
       "      <td>0.985062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">60</th>\n",
       "      <th>1</th>\n",
       "      <td>10.155516</td>\n",
       "      <td>0.825833</td>\n",
       "      <td>0.973842</td>\n",
       "      <td>0.973705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.382768</td>\n",
       "      <td>0.939650</td>\n",
       "      <td>0.979233</td>\n",
       "      <td>0.979290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.299946</td>\n",
       "      <td>0.948783</td>\n",
       "      <td>0.983127</td>\n",
       "      <td>0.983897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.135671</td>\n",
       "      <td>0.953433</td>\n",
       "      <td>0.986322</td>\n",
       "      <td>0.986244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.516332</td>\n",
       "      <td>0.956917</td>\n",
       "      <td>0.983626</td>\n",
       "      <td>0.984853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">70</th>\n",
       "      <th>1</th>\n",
       "      <td>9.999681</td>\n",
       "      <td>0.838617</td>\n",
       "      <td>0.975639</td>\n",
       "      <td>0.976572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.332960</td>\n",
       "      <td>0.938467</td>\n",
       "      <td>0.982927</td>\n",
       "      <td>0.981454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.460882</td>\n",
       "      <td>0.948567</td>\n",
       "      <td>0.982728</td>\n",
       "      <td>0.981877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.524399</td>\n",
       "      <td>0.953100</td>\n",
       "      <td>0.985423</td>\n",
       "      <td>0.984567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.012012</td>\n",
       "      <td>0.957217</td>\n",
       "      <td>0.985823</td>\n",
       "      <td>0.986393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">80</th>\n",
       "      <th>1</th>\n",
       "      <td>10.238461</td>\n",
       "      <td>0.832050</td>\n",
       "      <td>0.978135</td>\n",
       "      <td>0.976506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.353207</td>\n",
       "      <td>0.940483</td>\n",
       "      <td>0.981430</td>\n",
       "      <td>0.980281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.259863</td>\n",
       "      <td>0.947833</td>\n",
       "      <td>0.982428</td>\n",
       "      <td>0.980385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.131404</td>\n",
       "      <td>0.952500</td>\n",
       "      <td>0.984325</td>\n",
       "      <td>0.983005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.177033</td>\n",
       "      <td>0.953983</td>\n",
       "      <td>0.986022</td>\n",
       "      <td>0.985918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">90</th>\n",
       "      <th>1</th>\n",
       "      <td>10.493388</td>\n",
       "      <td>0.864467</td>\n",
       "      <td>0.978035</td>\n",
       "      <td>0.976605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.580061</td>\n",
       "      <td>0.943100</td>\n",
       "      <td>0.983427</td>\n",
       "      <td>0.981712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.973269</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.983327</td>\n",
       "      <td>0.983087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.398201</td>\n",
       "      <td>0.955500</td>\n",
       "      <td>0.983926</td>\n",
       "      <td>0.982634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.413992</td>\n",
       "      <td>0.957367</td>\n",
       "      <td>0.987720</td>\n",
       "      <td>0.986397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">99</th>\n",
       "      <th>1</th>\n",
       "      <td>10.126053</td>\n",
       "      <td>0.870267</td>\n",
       "      <td>0.976737</td>\n",
       "      <td>0.975432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.314359</td>\n",
       "      <td>0.941783</td>\n",
       "      <td>0.982129</td>\n",
       "      <td>0.982258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.465690</td>\n",
       "      <td>0.950117</td>\n",
       "      <td>0.983726</td>\n",
       "      <td>0.983180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.915742</td>\n",
       "      <td>0.953733</td>\n",
       "      <td>0.986621</td>\n",
       "      <td>0.986708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.070861</td>\n",
       "      <td>0.958783</td>\n",
       "      <td>0.988818</td>\n",
       "      <td>0.987702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  train_time  train_acc  test_acc  forget_acc\n",
       "percentage epoch                                             \n",
       "1          1       12.197492   0.862650  0.975739    0.975904\n",
       "           2       10.109900   0.940800  0.981330    0.981457\n",
       "           3       10.314586   0.948533  0.984026    0.983904\n",
       "           4       10.177313   0.954917  0.985523    0.985599\n",
       "           5       10.217436   0.958850  0.985623    0.985410\n",
       "10         1        9.943733   0.867033  0.978934    0.979042\n",
       "           2       10.187575   0.946133  0.981729    0.982036\n",
       "           3       10.533017   0.949667  0.985224    0.984780\n",
       "           4       10.228199   0.953500  0.986422    0.986589\n",
       "           5       10.616878   0.956467  0.986022    0.986776\n",
       "20         1       10.002365   0.874450  0.978335    0.976517\n",
       "           2       10.004757   0.945867  0.982728    0.981786\n",
       "           3       10.251070   0.951350  0.984325    0.984012\n",
       "           4       10.223609   0.955633  0.987121    0.985374\n",
       "           5       10.217983   0.958617  0.986122    0.986192\n",
       "30         1       10.159244   0.866150  0.976538    0.975385\n",
       "           2       10.183870   0.941867  0.983227    0.980879\n",
       "           3       10.238254   0.951067  0.982628    0.981485\n",
       "           4       10.343989   0.954683  0.983427    0.984339\n",
       "           5       10.358709   0.956150  0.986621    0.986765\n",
       "40         1       10.083722   0.872117  0.980731    0.979598\n",
       "           2       10.389214   0.946400  0.979633    0.980303\n",
       "           3       10.279586   0.952917  0.984125    0.984360\n",
       "           4       10.659853   0.954900  0.983626    0.984978\n",
       "           5       10.253969   0.956783  0.986821    0.987888\n",
       "50         1        9.902655   0.844583  0.976637    0.975370\n",
       "           2       10.267082   0.940717  0.978934    0.977443\n",
       "           3       10.229579   0.948850  0.981929    0.983064\n",
       "           4       10.100196   0.951517  0.985723    0.984787\n",
       "           5       10.076050   0.954100  0.986522    0.985062\n",
       "60         1       10.155516   0.825833  0.973842    0.973705\n",
       "           2       10.382768   0.939650  0.979233    0.979290\n",
       "           3        9.299946   0.948783  0.983127    0.983897\n",
       "           4       10.135671   0.953433  0.986322    0.986244\n",
       "           5       10.516332   0.956917  0.983626    0.984853\n",
       "70         1        9.999681   0.838617  0.975639    0.976572\n",
       "           2       10.332960   0.938467  0.982927    0.981454\n",
       "           3       10.460882   0.948567  0.982728    0.981877\n",
       "           4       10.524399   0.953100  0.985423    0.984567\n",
       "           5       10.012012   0.957217  0.985823    0.986393\n",
       "80         1       10.238461   0.832050  0.978135    0.976506\n",
       "           2       10.353207   0.940483  0.981430    0.980281\n",
       "           3       10.259863   0.947833  0.982428    0.980385\n",
       "           4       10.131404   0.952500  0.984325    0.983005\n",
       "           5       10.177033   0.953983  0.986022    0.985918\n",
       "90         1       10.493388   0.864467  0.978035    0.976605\n",
       "           2       10.580061   0.943100  0.983427    0.981712\n",
       "           3        9.973269   0.950000  0.983327    0.983087\n",
       "           4       10.398201   0.955500  0.983926    0.982634\n",
       "           5       10.413992   0.957367  0.987720    0.986397\n",
       "99         1       10.126053   0.870267  0.976737    0.975432\n",
       "           2       10.314359   0.941783  0.982129    0.982258\n",
       "           3       10.465690   0.950117  0.983726    0.983180\n",
       "           4        9.915742   0.953733  0.986621    0.986708\n",
       "           5       10.070861   0.958783  0.988818    0.987702"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.concat(results).set_index(['percentage', 'epoch'])\n",
    "\n",
    "results.to_csv('results/Unlearnable.csv')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997af4e9-fcac-4e5d-ba73-8fafc33ef4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
