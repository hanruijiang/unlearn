{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbae74ae-2cd5-4cd7-9a33-9f8ec2117853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "403b3846-9d50-4090-bde4-0409bd6df012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_original_dataset, load_deleted_dataset\n",
    "from models import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f070e1c-cde4-44db-8533-1aa4e940cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'Datasets/Features/'\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "PERCENTAGES = [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adc832b8-a9ba-4e86-8054-83c68fd4f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('./libraries/Unlearnable-Examples/'))\n",
    "import toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "babdf70c-98e0-4d26-b3db-93a14227a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/HanxunH/Unlearnable-Examples/blob/main/perturbation.py#L45\n",
    "\n",
    "EPSILON = 8\n",
    "NUM_STEPS = 1\n",
    "STEP_SIZE = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7170876-46e4-49b0-ac7a-e4cbedeb0726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/HanxunH/Unlearnable-Examples/blob/main/perturbation.py#L51\n",
    "# https://github.com/HanxunH/Unlearnable-Examples/blob/main/perturbation.py#L446\n",
    "\n",
    "noise_generator = toolbox.PerturbationTool(\n",
    "    epsilon=EPSILON / 255,\n",
    "    num_steps=NUM_STEPS,\n",
    "    step_size=STEP_SIZE / 255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc7b25b5-7572-4d3f-a999-78db6c9c4ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_random_noise(x):\n",
    "    \n",
    "    # https://github.com/HanxunH/Unlearnable-Examples/blob/main/dataset.py#L441\n",
    "    noise = noise_generator.random_noise(noise_shape=x.shape)\n",
    "    \n",
    "    # https://github.com/HanxunH/Unlearnable-Examples/blob/main/dataset.py#L448\n",
    "    noise = noise.mul(255).clamp_(0, 255)\n",
    "    \n",
    "    # https://github.com/HanxunH/Unlearnable-Examples/blob/main/perturbation.py#L451\n",
    "    x = x + noise.to(x.device)\n",
    "    x = torch.clamp(x, 0, 255)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c13a2159-60c2-4395-bb31-0fd7028ae9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, save_dir, train_set, test_set, forget_set):\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    train_x, train_y = train_set.tensors\n",
    "    forget_x, forget_y = forget_set.tensors\n",
    "    \n",
    "    forget_x = add_random_noise(forget_x)\n",
    "    \n",
    "    train_set = torch.utils.data.TensorDataset(\n",
    "        torch.concat([train_x, forget_x], dim=0), \n",
    "        torch.concat([train_y, forget_y], dim=0), \n",
    "    )\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    error = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True, drop_last=True)\n",
    "    \n",
    "    train_times = list()\n",
    "    train_accs, test_accs, forget_accs = list(), list(), list()\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        # train\n",
    "        \n",
    "        accs = list()\n",
    "        \n",
    "        train_time = 0\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x.cuda())\n",
    "            y = y.cuda()\n",
    "            loss = error(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_time += time.time() - start_time\n",
    "            \n",
    "            predicted = torch.argmax(output.data, dim=-1)\n",
    "            accs.append((predicted == y).float().mean().detach().cpu().numpy())\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "        train_times.append(train_time)\n",
    "        train_accs.append(np.mean(accs))\n",
    "        \n",
    "        # test\n",
    "            \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            x, y = test_set.tensors\n",
    "            \n",
    "            accs = list()\n",
    "            \n",
    "            for i in range(0, x.shape[0], BATCH_SIZE):\n",
    "            \n",
    "                output = model(x[i:i+BATCH_SIZE].cuda())\n",
    "\n",
    "                predicted = torch.argmax(output.data, dim=-1)\n",
    "                accs.append((predicted == y[i:i+BATCH_SIZE].cuda()).float().mean().detach().cpu().numpy())\n",
    "            \n",
    "            test_accs.append(np.mean(accs))\n",
    "            \n",
    "\n",
    "            x, y = forget_set.tensors\n",
    "\n",
    "            for i in range(0, x.shape[0], BATCH_SIZE):\n",
    "\n",
    "                output = model(x[i:i+BATCH_SIZE].cuda())\n",
    "\n",
    "                predicted = torch.argmax(output.data, dim=-1)\n",
    "                accs.append((predicted == y[i:i+BATCH_SIZE].cuda()).float().mean().detach().cpu().numpy())\n",
    "\n",
    "            forget_accs.append(np.mean(accs))\n",
    "        \n",
    "        # save\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, f'{(epoch+1):03d}.pt'))\n",
    "\n",
    "    return train_times, train_accs, test_accs, forget_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69f93ce0-4df5-41fe-ab4d-aef8c750ad58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff9b5c656424409ac3a6ae675a51ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = list()\n",
    "\n",
    "for percentage in tqdm(PERCENTAGES):\n",
    "    \n",
    "    model = CNN().cuda()\n",
    "        \n",
    "    model.load_state_dict(torch.load('./weights/init.pt'))\n",
    "    \n",
    "    train_set, test_set, forget_set = load_deleted_dataset(DATA_DIR, percentage)\n",
    "    \n",
    "    train_times, train_accs, test_accs, forget_accs = fit(model, f'weights/Unlearnable/{percentage}', train_set, test_set, forget_set)\n",
    "    \n",
    "    df = pd.DataFrame(zip(train_times, train_accs, test_accs, forget_accs), columns=['train_time', 'train_acc', 'test_acc', 'forget_acc'])\n",
    "    df['epoch'] = range(1, EPOCHS+1)\n",
    "    df['percentage'] = percentage\n",
    "    \n",
    "    results.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1ea734a-a103-47f6-a272-6873307012d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>train_time</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>forget_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage</th>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>12.394400</td>\n",
       "      <td>0.854800</td>\n",
       "      <td>0.979133</td>\n",
       "      <td>0.978916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.792596</td>\n",
       "      <td>0.942600</td>\n",
       "      <td>0.983726</td>\n",
       "      <td>0.983622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.864631</td>\n",
       "      <td>0.951767</td>\n",
       "      <td>0.986322</td>\n",
       "      <td>0.986069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.538467</td>\n",
       "      <td>0.954183</td>\n",
       "      <td>0.986022</td>\n",
       "      <td>0.986069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.659187</td>\n",
       "      <td>0.957767</td>\n",
       "      <td>0.988918</td>\n",
       "      <td>0.989081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">10</th>\n",
       "      <th>1</th>\n",
       "      <td>10.545051</td>\n",
       "      <td>0.853067</td>\n",
       "      <td>0.977636</td>\n",
       "      <td>0.977857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.654274</td>\n",
       "      <td>0.943933</td>\n",
       "      <td>0.981530</td>\n",
       "      <td>0.981911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.780971</td>\n",
       "      <td>0.952867</td>\n",
       "      <td>0.985423</td>\n",
       "      <td>0.985841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.817822</td>\n",
       "      <td>0.954033</td>\n",
       "      <td>0.986022</td>\n",
       "      <td>0.985342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.355096</td>\n",
       "      <td>0.958283</td>\n",
       "      <td>0.987919</td>\n",
       "      <td>0.987774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20</th>\n",
       "      <th>1</th>\n",
       "      <td>10.333398</td>\n",
       "      <td>0.857167</td>\n",
       "      <td>0.973942</td>\n",
       "      <td>0.973973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.213562</td>\n",
       "      <td>0.941700</td>\n",
       "      <td>0.980731</td>\n",
       "      <td>0.980650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.539955</td>\n",
       "      <td>0.949483</td>\n",
       "      <td>0.985423</td>\n",
       "      <td>0.984920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.011899</td>\n",
       "      <td>0.953117</td>\n",
       "      <td>0.985224</td>\n",
       "      <td>0.985329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.762937</td>\n",
       "      <td>0.956733</td>\n",
       "      <td>0.984724</td>\n",
       "      <td>0.984239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">30</th>\n",
       "      <th>1</th>\n",
       "      <td>10.544111</td>\n",
       "      <td>0.837133</td>\n",
       "      <td>0.973842</td>\n",
       "      <td>0.974137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.545203</td>\n",
       "      <td>0.939650</td>\n",
       "      <td>0.978335</td>\n",
       "      <td>0.978382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.942711</td>\n",
       "      <td>0.949267</td>\n",
       "      <td>0.984325</td>\n",
       "      <td>0.984518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.773436</td>\n",
       "      <td>0.953817</td>\n",
       "      <td>0.987320</td>\n",
       "      <td>0.986301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.393672</td>\n",
       "      <td>0.957033</td>\n",
       "      <td>0.986022</td>\n",
       "      <td>0.984446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">40</th>\n",
       "      <th>1</th>\n",
       "      <td>10.614304</td>\n",
       "      <td>0.843233</td>\n",
       "      <td>0.972444</td>\n",
       "      <td>0.972013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.487042</td>\n",
       "      <td>0.938583</td>\n",
       "      <td>0.979832</td>\n",
       "      <td>0.979098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.400898</td>\n",
       "      <td>0.946533</td>\n",
       "      <td>0.982827</td>\n",
       "      <td>0.981685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.895097</td>\n",
       "      <td>0.953767</td>\n",
       "      <td>0.982728</td>\n",
       "      <td>0.983861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.716718</td>\n",
       "      <td>0.954600</td>\n",
       "      <td>0.985723</td>\n",
       "      <td>0.985801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">50</th>\n",
       "      <th>1</th>\n",
       "      <td>10.580053</td>\n",
       "      <td>0.856017</td>\n",
       "      <td>0.978035</td>\n",
       "      <td>0.975719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.867815</td>\n",
       "      <td>0.938067</td>\n",
       "      <td>0.978734</td>\n",
       "      <td>0.977393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.512452</td>\n",
       "      <td>0.948017</td>\n",
       "      <td>0.980431</td>\n",
       "      <td>0.981040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.861669</td>\n",
       "      <td>0.954467</td>\n",
       "      <td>0.986422</td>\n",
       "      <td>0.985362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.631861</td>\n",
       "      <td>0.955567</td>\n",
       "      <td>0.987420</td>\n",
       "      <td>0.986211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">60</th>\n",
       "      <th>1</th>\n",
       "      <td>10.281838</td>\n",
       "      <td>0.862183</td>\n",
       "      <td>0.977436</td>\n",
       "      <td>0.976682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.508565</td>\n",
       "      <td>0.943183</td>\n",
       "      <td>0.980931</td>\n",
       "      <td>0.981354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.673586</td>\n",
       "      <td>0.950767</td>\n",
       "      <td>0.982728</td>\n",
       "      <td>0.983223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.674185</td>\n",
       "      <td>0.955100</td>\n",
       "      <td>0.987520</td>\n",
       "      <td>0.987157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.916331</td>\n",
       "      <td>0.957500</td>\n",
       "      <td>0.989217</td>\n",
       "      <td>0.988787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">70</th>\n",
       "      <th>1</th>\n",
       "      <td>10.543548</td>\n",
       "      <td>0.849433</td>\n",
       "      <td>0.975739</td>\n",
       "      <td>0.975381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.530491</td>\n",
       "      <td>0.940883</td>\n",
       "      <td>0.981929</td>\n",
       "      <td>0.981338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.765501</td>\n",
       "      <td>0.951533</td>\n",
       "      <td>0.984225</td>\n",
       "      <td>0.983433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.790347</td>\n",
       "      <td>0.955167</td>\n",
       "      <td>0.988019</td>\n",
       "      <td>0.987623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.482557</td>\n",
       "      <td>0.956917</td>\n",
       "      <td>0.986821</td>\n",
       "      <td>0.987066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">80</th>\n",
       "      <th>1</th>\n",
       "      <td>10.386471</td>\n",
       "      <td>0.831133</td>\n",
       "      <td>0.976538</td>\n",
       "      <td>0.975662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.656862</td>\n",
       "      <td>0.941017</td>\n",
       "      <td>0.981030</td>\n",
       "      <td>0.980609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.508404</td>\n",
       "      <td>0.951750</td>\n",
       "      <td>0.982528</td>\n",
       "      <td>0.982264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.474500</td>\n",
       "      <td>0.953067</td>\n",
       "      <td>0.985723</td>\n",
       "      <td>0.985418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.656532</td>\n",
       "      <td>0.955917</td>\n",
       "      <td>0.986022</td>\n",
       "      <td>0.985125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">90</th>\n",
       "      <th>1</th>\n",
       "      <td>10.788838</td>\n",
       "      <td>0.834017</td>\n",
       "      <td>0.975339</td>\n",
       "      <td>0.975059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.536884</td>\n",
       "      <td>0.937917</td>\n",
       "      <td>0.979533</td>\n",
       "      <td>0.978261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.703653</td>\n",
       "      <td>0.947467</td>\n",
       "      <td>0.984325</td>\n",
       "      <td>0.983118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.688255</td>\n",
       "      <td>0.952850</td>\n",
       "      <td>0.984924</td>\n",
       "      <td>0.984992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.419155</td>\n",
       "      <td>0.955633</td>\n",
       "      <td>0.988019</td>\n",
       "      <td>0.987631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">99</th>\n",
       "      <th>1</th>\n",
       "      <td>10.636824</td>\n",
       "      <td>0.851500</td>\n",
       "      <td>0.976338</td>\n",
       "      <td>0.972854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.538013</td>\n",
       "      <td>0.935383</td>\n",
       "      <td>0.980132</td>\n",
       "      <td>0.979450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.610987</td>\n",
       "      <td>0.949133</td>\n",
       "      <td>0.982328</td>\n",
       "      <td>0.980717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.454468</td>\n",
       "      <td>0.951583</td>\n",
       "      <td>0.983227</td>\n",
       "      <td>0.984116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.681539</td>\n",
       "      <td>0.953150</td>\n",
       "      <td>0.986322</td>\n",
       "      <td>0.985484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  train_time  train_acc  test_acc  forget_acc\n",
       "percentage epoch                                             \n",
       "1          1       12.394400   0.854800  0.979133    0.978916\n",
       "           2       10.792596   0.942600  0.983726    0.983622\n",
       "           3       10.864631   0.951767  0.986322    0.986069\n",
       "           4       10.538467   0.954183  0.986022    0.986069\n",
       "           5       10.659187   0.957767  0.988918    0.989081\n",
       "10         1       10.545051   0.853067  0.977636    0.977857\n",
       "           2       10.654274   0.943933  0.981530    0.981911\n",
       "           3       10.780971   0.952867  0.985423    0.985841\n",
       "           4       10.817822   0.954033  0.986022    0.985342\n",
       "           5       10.355096   0.958283  0.987919    0.987774\n",
       "20         1       10.333398   0.857167  0.973942    0.973973\n",
       "           2       11.213562   0.941700  0.980731    0.980650\n",
       "           3       10.539955   0.949483  0.985423    0.984920\n",
       "           4       11.011899   0.953117  0.985224    0.985329\n",
       "           5       10.762937   0.956733  0.984724    0.984239\n",
       "30         1       10.544111   0.837133  0.973842    0.974137\n",
       "           2       11.545203   0.939650  0.978335    0.978382\n",
       "           3       10.942711   0.949267  0.984325    0.984518\n",
       "           4       10.773436   0.953817  0.987320    0.986301\n",
       "           5       10.393672   0.957033  0.986022    0.984446\n",
       "40         1       10.614304   0.843233  0.972444    0.972013\n",
       "           2       10.487042   0.938583  0.979832    0.979098\n",
       "           3       10.400898   0.946533  0.982827    0.981685\n",
       "           4       10.895097   0.953767  0.982728    0.983861\n",
       "           5       10.716718   0.954600  0.985723    0.985801\n",
       "50         1       10.580053   0.856017  0.978035    0.975719\n",
       "           2       10.867815   0.938067  0.978734    0.977393\n",
       "           3       10.512452   0.948017  0.980431    0.981040\n",
       "           4       10.861669   0.954467  0.986422    0.985362\n",
       "           5       10.631861   0.955567  0.987420    0.986211\n",
       "60         1       10.281838   0.862183  0.977436    0.976682\n",
       "           2       10.508565   0.943183  0.980931    0.981354\n",
       "           3       10.673586   0.950767  0.982728    0.983223\n",
       "           4       10.674185   0.955100  0.987520    0.987157\n",
       "           5       10.916331   0.957500  0.989217    0.988787\n",
       "70         1       10.543548   0.849433  0.975739    0.975381\n",
       "           2       10.530491   0.940883  0.981929    0.981338\n",
       "           3       10.765501   0.951533  0.984225    0.983433\n",
       "           4       10.790347   0.955167  0.988019    0.987623\n",
       "           5       10.482557   0.956917  0.986821    0.987066\n",
       "80         1       10.386471   0.831133  0.976538    0.975662\n",
       "           2       10.656862   0.941017  0.981030    0.980609\n",
       "           3       10.508404   0.951750  0.982528    0.982264\n",
       "           4       10.474500   0.953067  0.985723    0.985418\n",
       "           5       10.656532   0.955917  0.986022    0.985125\n",
       "90         1       10.788838   0.834017  0.975339    0.975059\n",
       "           2       10.536884   0.937917  0.979533    0.978261\n",
       "           3       10.703653   0.947467  0.984325    0.983118\n",
       "           4       10.688255   0.952850  0.984924    0.984992\n",
       "           5       10.419155   0.955633  0.988019    0.987631\n",
       "99         1       10.636824   0.851500  0.976338    0.972854\n",
       "           2       10.538013   0.935383  0.980132    0.979450\n",
       "           3       10.610987   0.949133  0.982328    0.980717\n",
       "           4       10.454468   0.951583  0.983227    0.984116\n",
       "           5       10.681539   0.953150  0.986322    0.985484"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.concat(results).set_index(['percentage', 'epoch'])\n",
    "\n",
    "results.to_csv('results/Unlearnable.csv')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997af4e9-fcac-4e5d-ba73-8fafc33ef4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
