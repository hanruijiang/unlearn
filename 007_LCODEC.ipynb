{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbae74ae-2cd5-4cd7-9a33-9f8ec2117853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import io\n",
    "import contextlib\n",
    "\n",
    "import torch\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "403b3846-9d50-4090-bde4-0409bd6df012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_original_dataset, load_deleted_dataset\n",
    "from models import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f070e1c-cde4-44db-8533-1aa4e940cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'Datasets/Features/'\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "PERCENTAGES = [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adc832b8-a9ba-4e86-8054-83c68fd4f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('./libraries/LCODEC-deep-unlearning/'))\n",
    "sys.path.append(os.path.abspath('./libraries/LCODEC-deep-unlearning/scrub/'))\n",
    "\n",
    "from scrub_tools import inp_perturb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "babdf70c-98e0-4d26-b3db-93a14227a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/vsingh-group/LCODEC-deep-unlearning/blob/main/scrub/scrub_scripts/mnist_logistic.sh\n",
    "\n",
    "class args:\n",
    "    lr = 0.001\n",
    "    batch_size = 256\n",
    "    scrub_batch_size = 256\n",
    "    weight_decay = 0.01\n",
    "    n_perturbations = 1000\n",
    "    selectionType = 'Full'\n",
    "    order = 'BP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c13a2159-60c2-4395-bb31-0fd7028ae9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, save_dir, train_set, test_set, forget_set):\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # https://github.com/vsingh-group/LCODEC-deep-unlearning/blob/main/scrub/multi_scrub.py#L52\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    # https://github.com/vsingh-group/LCODEC-deep-unlearning/blob/main/scrub/multi_scrub.py#L77\n",
    "    forget_loader = torch.utils.data.DataLoader(forget_set, batch_size = args.batch_size, shuffle = True, drop_last=False)\n",
    "    \n",
    "    train_times = list()\n",
    "    train_accs, test_accs, forget_accs = list(), list(), list()\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        # train\n",
    "        \n",
    "        train_time = 0\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for x, y in forget_loader:\n",
    "        \n",
    "            model.train()\n",
    "\n",
    "            # https://github.com/vsingh-group/LCODEC-deep-unlearning/blob/main/scrub/multi_scrub.py#L94\n",
    "            scrub_dataset = torch.utils.data.TensorDataset(x, y)\n",
    "\n",
    "            # https://github.com/vsingh-group/LCODEC-deep-unlearning/blob/main/scrub/multi_scrub.py#L120\n",
    "            optim = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "            with io.StringIO() as text_output:\n",
    "                with contextlib.redirect_stdout(text_output):\n",
    "                    \n",
    "                    # https://github.com/vsingh-group/LCODEC-deep-unlearning/blob/main/scrub/multi_scrub.py#L122\n",
    "                    foci_val, updatedSD, samplossbefore, samplossafter, gradnormbefore, gradnormafter = inp_perturb(model, scrub_dataset, criterion, args, optim, device=0, outString=None)\n",
    "\n",
    "            # https://github.com/vsingh-group/LCODEC-deep-unlearning/blob/main/scrub/multi_scrub.py#L124\n",
    "            m = copy.deepcopy(model)\n",
    "            m.load_state_dict(updatedSD)\n",
    "            model = m\n",
    "            \n",
    "            train_time += time.time() - start_time\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "        train_times.append(train_time)\n",
    "        \n",
    "        # test\n",
    "            \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            x, y = train_set.tensors\n",
    "            \n",
    "            accs = list()\n",
    "            \n",
    "            for i in range(0, x.shape[0], BATCH_SIZE):\n",
    "            \n",
    "                output = model(x[i:i+BATCH_SIZE].cuda())\n",
    "\n",
    "                predicted = torch.argmax(output.data, dim=-1)\n",
    "                accs.append((predicted == y[i:i+BATCH_SIZE].cuda()).float().mean().detach().cpu().numpy())\n",
    "            \n",
    "            train_accs.append(np.mean(accs))\n",
    "            \n",
    "            x, y = test_set.tensors\n",
    "\n",
    "            \n",
    "            accs = list()\n",
    "            \n",
    "            for i in range(0, x.shape[0], BATCH_SIZE):\n",
    "            \n",
    "                output = model(x[i:i+BATCH_SIZE].cuda())\n",
    "\n",
    "                predicted = torch.argmax(output.data, dim=-1)\n",
    "                accs.append((predicted == y[i:i+BATCH_SIZE].cuda()).float().mean().detach().cpu().numpy())\n",
    "            \n",
    "            test_accs.append(np.mean(accs))\n",
    "            \n",
    "\n",
    "            x, y = forget_set.tensors\n",
    "\n",
    "            for i in range(0, x.shape[0], BATCH_SIZE):\n",
    "\n",
    "                output = model(x[i:i+BATCH_SIZE].cuda())\n",
    "\n",
    "                predicted = torch.argmax(output.data, dim=-1)\n",
    "                accs.append((predicted == y[i:i+BATCH_SIZE].cuda()).float().mean().detach().cpu().numpy())\n",
    "\n",
    "            forget_accs.append(np.mean(accs))\n",
    "        \n",
    "        # save\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, f'{(epoch+1):03d}.pt'))\n",
    "\n",
    "    return train_times, train_accs, test_accs, forget_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69f93ce0-4df5-41fe-ab4d-aef8c750ad58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a591f3cca0ce4451b7e4482bb186f367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = list()\n",
    "\n",
    "for percentage in tqdm(PERCENTAGES):\n",
    "    \n",
    "    model = CNN().cuda()\n",
    "\n",
    "    # https://github.com/vsingh-group/LCODEC-deep-unlearning/blob/main/scrub/multi_scrub.py#L49\n",
    "    model.load_state_dict(torch.load('./weights/original/005.pt'))\n",
    "    \n",
    "    train_set, test_set, forget_set = load_deleted_dataset(DATA_DIR, percentage)\n",
    "    \n",
    "    train_times, train_accs, test_accs, forget_accs = fit(model, f'weights/LCODEC/{percentage}', train_set, test_set, forget_set)\n",
    "    \n",
    "    df = pd.DataFrame(zip(train_times, train_accs, test_accs, forget_accs), columns=['train_time', 'train_acc', 'test_acc', 'forget_acc'])\n",
    "    df['epoch'] = range(1, EPOCHS+1)\n",
    "    df['percentage'] = percentage\n",
    "    \n",
    "    results.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1ea734a-a103-47f6-a272-6873307012d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>train_time</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>forget_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage</th>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <td>9.700272</td>\n",
       "      <td>0.987934</td>\n",
       "      <td>0.987420</td>\n",
       "      <td>0.987387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>1</th>\n",
       "      <td>86.889040</td>\n",
       "      <td>0.987059</td>\n",
       "      <td>0.987021</td>\n",
       "      <td>0.987026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <th>1</th>\n",
       "      <td>160.117764</td>\n",
       "      <td>0.810896</td>\n",
       "      <td>0.808606</td>\n",
       "      <td>0.804279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <th>1</th>\n",
       "      <td>245.824888</td>\n",
       "      <td>0.098558</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <th>1</th>\n",
       "      <td>324.004524</td>\n",
       "      <td>0.098389</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <th>1</th>\n",
       "      <td>408.564574</td>\n",
       "      <td>0.098714</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <th>1</th>\n",
       "      <td>486.597490</td>\n",
       "      <td>0.099542</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <th>1</th>\n",
       "      <td>567.409597</td>\n",
       "      <td>0.098857</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <th>1</th>\n",
       "      <td>660.018223</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <th>1</th>\n",
       "      <td>740.346546</td>\n",
       "      <td>0.097739</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <th>1</th>\n",
       "      <td>813.422998</td>\n",
       "      <td>0.095943</td>\n",
       "      <td>0.097943</td>\n",
       "      <td>0.098589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  train_time  train_acc  test_acc  forget_acc\n",
       "percentage epoch                                             \n",
       "1          1        9.700272   0.987934  0.987420    0.987387\n",
       "10         1       86.889040   0.987059  0.987021    0.987026\n",
       "20         1      160.117764   0.810896  0.808606    0.804279\n",
       "30         1      245.824888   0.098558  0.097943    0.098637\n",
       "40         1      324.004524   0.098389  0.097943    0.098836\n",
       "50         1      408.564574   0.098714  0.097943    0.098521\n",
       "60         1      486.597490   0.099542  0.097943    0.098118\n",
       "70         1      567.409597   0.098857  0.097943    0.098536\n",
       "80         1      660.018223   0.099500  0.097943    0.098421\n",
       "90         1      740.346546   0.097739  0.097943    0.098669\n",
       "99         1      813.422998   0.095943  0.097943    0.098589"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.concat(results).set_index(['percentage', 'epoch'])\n",
    "\n",
    "results.to_csv('results/LCODEC.csv')\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997af4e9-fcac-4e5d-ba73-8fafc33ef4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
